{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8e286cd-5666-43de-bac8-19604e024fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "947c01b7-e9c8-487d-9cc2-4bbbf1d4c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_loss(model, loader):\n",
    "    correct=0\n",
    "    total=0\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        output=model(images)\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        total+=labels.shape[0]\n",
    "        correct += pred.eq(labels.data.view_as(pred)).sum()\n",
    "        loss=loss_func(output, labels)\n",
    "    acc=100.*correct/total\n",
    "    return acc.detach().cpu().numpy(), loss.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "056ad81f-cc59-4572-a00d-7d7f9e921cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f244f8e7-8fc3-4fa5-bd6d-fe056f199989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b23103a-6c3e-42e2-beec-a6a9df927762",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8d894d-2ecb-4c3f-9ede-f7c6d8de28ae",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0bb003cd-1ea1-4529-a861-bef6d0ccfcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnimalCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(AnimalCNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.convolution_stack = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3,3), stride=1, padding=1),   #in = 3x32x32; out = 32x32x32\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2)),      # in = 32x32x32:  out = 32x16x16\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), stride=1, padding=1),   #in = 32x16x16; out = 64x16x16\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), stride=1, padding=1),   #in = 32x16x16; out = 64x16x16\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2)),      # in = 64x16x16:  out = 64x8x8\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), stride=1, padding=1),   #in = 64x8x8; out = 128x8x8\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3,3), stride=1, padding=1),   #in = 64x8x8; out = 128x8x8\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2))      # in = 128x8x8:  out = 128x4x4\n",
    "        )\n",
    "        self.linear_stack=nn.Sequential(\n",
    "            nn.Linear(128*4*4, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512,10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convolution_stack(x)\n",
    "        x=self.flatten(x)\n",
    "        x=self.linear_stack(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b3880b1c-4d22-4950-aafe-df2c7df47278",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=AnimalCNN().to(device)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9,0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fa16f4d9-4b5d-431c-807f-7666c475b225",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=5\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_acc=[]\n",
    "test_acc=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5d49d8fd-b713-4392-bd00-439f9e139b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Test Loss=0.685, Test Accuracy=60.0\n",
      "Epoch 2/5, Test Loss=0.742, Test Accuracy=67.4\n",
      "Epoch 3/5, Test Loss=1.83, Test Accuracy=64.5\n",
      "Epoch 4/5, Test Loss=1.17, Test Accuracy=74.7\n",
      "Epoch 5/5, Test Loss=0.884, Test Accuracy=77.7\n",
      "CPU times: total: 1min 52s\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for idx, (images, labels) in enumerate(trainloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss=loss_func(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        acc, loss = get_acc_loss(model, trainloader)\n",
    "        train_acc.append(acc)\n",
    "        train_loss.append(loss)\n",
    "        \n",
    "        acc, loss = get_acc_loss(model, testloader)            \n",
    "        test_acc.append(acc)\n",
    "        test_loss.append(loss)\n",
    "\n",
    "\n",
    "  #  if epoch%10==9:\n",
    "    print(f'Epoch {epoch+1}/{n_epochs}, Test Loss={loss.item():.3}, Test Accuracy={acc:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0aab74c2-615f-49f5-b8eb-bfd7f4e75742",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnimalResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(AnimalResNet, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.first_convolution_stack = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(3,3), stride=1, padding=1),   #in = 3x32x32; out = 64x32x32\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2))      # in = 64x32x32:  out = 64x16x16\n",
    "        )\n",
    "        self.res_convolution_stack1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), stride=1, padding=1),   #in = 64x16x16; out = 64x16x16\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), stride=1, padding=1),   #in = 64x16x16; out = 64x16x16\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "        self.bottleneck1=nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), stride=1, padding=1),   #in = 64x16x16; out = 128x16x16\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(kernel_size=(2,2))  #in = 128x16x16; out = 128x8x8\n",
    "        )\n",
    "            \n",
    "        self.res_convolution_stack2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3,3), stride=1, padding=1),   #in = 128x8x8; out = 128x18x8\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3,3), stride=1, padding=1),   #in = 128x8x8; out = 128x8x8\n",
    "            nn.BatchNorm2d(128)\n",
    "        )\n",
    "        self.bottleneck2=nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3,3), stride=1, padding=1),   #in = 128x8x8; out = 128x8x8\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(kernel_size=(2,2))  #in = 128x8x8; out = 128x4x4\n",
    "        )\n",
    "        self.linear_stack=nn.Sequential(\n",
    "            nn.Linear(128*4*4, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512,10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "       \n",
    "        x = self.first_convolution_stack(x)\n",
    "        save=x \n",
    "        x=self.res_convolution_stack1(x)\n",
    "        x=x+save\n",
    "        x=self.bottleneck1(x)\n",
    "        save=x\n",
    "        x=self.res_convolution_stack2(x)\n",
    "        x=x+save\n",
    "        x=self.bottleneck2(x)\n",
    "\n",
    "        x=self.flatten(x)\n",
    "\n",
    "        x=self.linear_stack(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "289f25d4-fe91-4f10-9aca-b7b2057e0d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=AnimalResNet().to(device)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr=0.001, betas=(0.9,0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2051aea8-8107-4bd3-8ccc-d5d7434e5c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=5\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_acc=[]\n",
    "test_acc=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1d22b234-f6f6-4360-84e6-1a0d2f7f0462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Test Loss=1.17, Test Accuracy=65.1\n",
      "Epoch 2/5, Test Loss=1.39, Test Accuracy=71.9\n",
      "Epoch 3/5, Test Loss=0.409, Test Accuracy=75.8\n",
      "Epoch 4/5, Test Loss=0.421, Test Accuracy=77.9\n",
      "Epoch 5/5, Test Loss=0.258, Test Accuracy=80.2\n",
      "CPU times: total: 1min 50s\n",
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model2.train()\n",
    "    for idx, (images, labels) in enumerate(trainloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model2(images)\n",
    "        loss=loss_func(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    model2.eval()\n",
    "    with torch.inference_mode():\n",
    "        acc, loss = get_acc_loss(model2, trainloader)\n",
    "        train_acc.append(acc)\n",
    "        train_loss.append(loss)\n",
    "        \n",
    "        acc, loss = get_acc_loss(model2, testloader)            \n",
    "        test_acc.append(acc)\n",
    "        test_loss.append(loss)\n",
    "\n",
    "\n",
    "  #  if epoch%10==9:\n",
    "    print(f'Epoch {epoch+1}/{n_epochs}, Test Loss={loss.item():.3}, Test Accuracy={acc:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f066d4d6-9e72-48fe-a59c-edc816b52393",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
